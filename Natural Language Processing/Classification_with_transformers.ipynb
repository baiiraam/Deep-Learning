{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbPxFgSivb4QGDn7LnJ+Gd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRT_6N2EevNw"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import list_datasets\n",
        "\n",
        "all_dataset = list(list_datasets())\n",
        "print(f\"total number of datasets: {len(all_dataset)}\")\n",
        "print(f\"first 10 datasets: {all_dataset[:10]}\")"
      ],
      "metadata": {
        "id": "8dw5CHvqexaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "id": "jcnlFZACfSII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "emotions = load_dataset(\"emotion\")\n",
        "print(emotions)"
      ],
      "metadata": {
        "id": "XlrTmt2Wf4y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = emotions[\"train\"]\n",
        "train_ds"
      ],
      "metadata": {
        "id": "bS4SCIC6gB3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "id": "4KJ78xPvgxVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.features"
      ],
      "metadata": {
        "id": "5vjL_2YDg47O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]"
      ],
      "metadata": {
        "id": "15vL-nnFg67r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0][\"text\"]"
      ],
      "metadata": {
        "id": "9InNJaxxhCFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[\"text\"][:5]"
      ],
      "metadata": {
        "id": "qbZBPCQFhOkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What if my dataset is not on the hub"
      ],
      "metadata": {
        "id": "9RQg7EQqhcS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://huggingface.co/datasets/transformersbook/emotion-train-split/raw/main/train.txt\"\n",
        "!wget {dataset_url}"
      ],
      "metadata": {
        "id": "Cr6J_ZAWhkfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 1 train.txt"
      ],
      "metadata": {
        "id": "rj6h_HyEhRAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 3 train.txt"
      ],
      "metadata": {
        "id": "31UuQ3L5iSuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_local = load_dataset('csv', data_files = 'train.txt', sep = ';', names = ['text', 'label'])"
      ],
      "metadata": {
        "id": "90fsL45siDYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From datasets to DataFrames"
      ],
      "metadata": {
        "id": "DDp3PmhkjKbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "emotions.set_format(type = 'pandas')\n",
        "df = emotions['train'][:]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qMq9df00irZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row):\n",
        "  return emotions['train'].features['label'].int2str(row)\n",
        "\n",
        "df['label_name'] = df['label'].apply(label_int2str)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "kdU70pdWjJpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['label_name'].value_counts().plot.barh()\n",
        "plt.title('Frequency of classes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BRs_K3oGj_W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Words per Tweet'] = df['text'].str.split().apply(len)\n",
        "df.boxplot('Words per Tweet', by='label_name', grid=False, showfliers=False, color='black')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3UM36LkNk3cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Words per Tweet'] = df['text'].str.split().apply(len)\n",
        "df.boxplot('Words per Tweet', by='label_name', grid=False, showfliers=True, color='black')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0wqARq7ImNqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "MJNTwRaalqBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format()"
      ],
      "metadata": {
        "id": "tog0ItwzmFVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Character Tokenization"
      ],
      "metadata": {
        "id": "7nImaTuKmYJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Just a random text for the sake of purpose'\n",
        "tokenized_text = list(text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "MX5H1fNYmvRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n",
        "token2idx"
      ],
      "metadata": {
        "id": "IEEYfL27mss2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [token2idx[token] for token in tokenized_text]\n",
        "print(input_ids)"
      ],
      "metadata": {
        "id": "gyO8_5FPmrvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input_ids = tf.constant(input_ids)\n",
        "one_hot_encodings = tf.one_hot(input_ids, len(token2idx))\n",
        "print(one_hot_encodings.shape)"
      ],
      "metadata": {
        "id": "fbi2RNHjoY6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Token: {tokenized_text[0]}\")\n",
        "print(f\"Tensor index: {input_ids[0]}\")\n",
        "print(f\"One-hot: {one_hot_encodings[0]}\")"
      ],
      "metadata": {
        "id": "rZ9e0gi0n2iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encodings"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8D68SiacozZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Tokenization"
      ],
      "metadata": {
        "id": "7GECIfUYpBkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts = text.split()"
      ],
      "metadata": {
        "id": "dBZaNldppfrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts"
      ],
      "metadata": {
        "id": "WalbvdMKpcbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subword Tokenization"
      ],
      "metadata": {
        "id": "-__BnlQBprGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "Wrh2f674p6t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same but more specific\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "J2PBrHffsX7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text)"
      ],
      "metadata": {
        "id": "tetrJnt8uPiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "KuxTiP-JuTx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_tokens_to_string(tokens))"
      ],
      "metadata": {
        "id": "EThDvENnzyZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "HJNeJF9jz3N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "id": "vrSDap720H2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_input_names"
      ],
      "metadata": {
        "id": "JU02Oj6J0M89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing the Whole Dataset"
      ],
      "metadata": {
        "id": "E6wydmrN0PWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch['text'], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "zTi5gVb402ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize(emotions['train'][:2]))"
      ],
      "metadata": {
        "id": "7Y1e7Hrm1DHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "7Ac8xpHG1JZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# python has map\n",
        "# huggingface datasets also has map\n",
        "# batch_size = None, max length sentence has no padding, all data is sent"
      ],
      "metadata": {
        "id": "b5J6RM9g1ZSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers as feature extractors"
      ],
      "metadata": {
        "id": "uHSFZR3r2C4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF for tensorflow in huggingface -->\n",
        "# cuda -- GPU"
      ],
      "metadata": {
        "id": "iFq0njhx3GS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch\n",
        "\n",
        "model_ckpt = 'distilbert-base-uncased'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AutoModel.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "id": "fL7H5GXo2KIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'this is a text'\n",
        "inputs = tokenizer(text, return_tensors = 'pt')\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "ZODsZYId2GiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "print(outputs.last_hidden_state.size())"
      ],
      "metadata": {
        "id": "Pd3Ge4Ck3sAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.items()"
      ],
      "metadata": {
        "id": "lUv-YtMe4KJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "id": "A0nGngp44d0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])"
      ],
      "metadata": {
        "id": "EJB2grwY4lo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "id": "guOeAPWj5l1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.last_hidden_state[:, 0].shape"
      ],
      "metadata": {
        "id": "5OMXZibN5HXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hidden_states(batch):\n",
        "  inputs = {k: v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
        "  with torch.no_grad():\n",
        "    last_hidden_state = model(**inputs).last_hidden_state\n",
        "  return {'hidden_states': last_hidden_state[:, 0].cpu().numpy()}\n"
      ],
      "metadata": {
        "id": "BhsQJ3lS5pk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
      ],
      "metadata": {
        "id": "gxpZyU4d6tJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched = True)"
      ],
      "metadata": {
        "id": "2C3hrgKE7AvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trying error\n",
        "def extract_hidden_states_2(batch):\n",
        "  inputs = {k: v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
        "  with torch.no_grad():\n",
        "    last_hidden_state = model(**inputs).last_hidden_state\n",
        "  return last_hidden_state[:, 0].cpu().numpy()\n",
        "\n",
        "emotions_hidden = emotions_encoded.map(extract_hidden_states_2, batched = True)"
      ],
      "metadata": {
        "id": "o3nHORXc7WGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_hidden"
      ],
      "metadata": {
        "id": "VMp2X_4J7m1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_hidden['train'][0]"
      ],
      "metadata": {
        "id": "wKqTgIRN8JvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.array(emotions_hidden['train']['hidden_states'])\n",
        "X_valid = np.array(emotions_hidden['validation']['hidden_states'])\n",
        "y_train = np.array(emotions_hidden['train']['label'])\n",
        "y_valid = np.array(emotions_hidden['validation']['label'])"
      ],
      "metadata": {
        "id": "JHHH2FUa8iR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the training data"
      ],
      "metadata": {
        "id": "mt-TYBKF8-w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from umap import UMAP\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "mapper = UMAP(n_components=2, metric='cosine').fit(X_scaled)\n",
        "df_emb = pd.DataFrame(mapper.embedding_, columns = ['X', 'Y'])\n",
        "df_emb['label'] = y_train\n",
        "df_emb.head()"
      ],
      "metadata": {
        "id": "DImTNub69UKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# umap\n",
        "fig, ax = plt.subplots(2, 3, figsize=(7, 5))\n",
        "ax = ax.flatten()\n",
        "cmaps = ['Greys', 'Blues', 'Oranges', 'Reds', 'Purples', 'Greens']\n",
        "labels = emotions['train'].features['label']\n",
        "for i, (label, cmap) in enumerate(zip(labels.names, cmaps)):\n",
        "  df_emb_sub = df_emb.query(f'label == {i}')\n",
        "  ax[i].hexbin(df_emb_sub['X'], df_emb_sub['Y'], cmap = cmap,\n",
        "               gridsize=20, linewidths = (0, ))\n",
        "  ax[i].set_title(label)\n",
        "  ax[i].set_xticks([]), ax[i].set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5kuDiFjm9y3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a simple classifier"
      ],
      "metadata": {
        "id": "o6a1cidy_-nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(max_iter = 3000)\n",
        "lr_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6HeU8Q_rBKHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "iujnuOIiBUTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy = 'most_frequent')\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "dummy_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "iqFOTufyBW6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "  cm = confusion_matrix(y_true, y_preds, normalize='true')\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "  disp.plot(cmap='Blues', values_format='.2f', ax=ax, colorbar=False)\n",
        "  plt.title('Normalized confusion matrix')\n",
        "  plt.show()\n",
        "\n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "plot_confusion_matrix(y_preds, y_valid, labels.names)"
      ],
      "metadata": {
        "id": "CfUbZquUBiT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning Transformers"
      ],
      "metadata": {
        "id": "QcsYnOyaYJPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_skpt = 'distilbert-base-uncased'\n",
        "num_labels = 6\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels = num_labels).to(device)"
      ],
      "metadata": {
        "id": "zdQPgADMENuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average = 'weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc, 'f1': f1}"
      ],
      "metadata": {
        "id": "JJuYQYdhYQ9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "EwNOv6O4YRRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "logging_steps = len(emotions_encoded['train']) // batch_size\n",
        "model_name = f'{model_ckpt}-finetuned-emotion'\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = model_name,\n",
        "    num_train_epochs = 2,\n",
        "    learning_rate = 2e-5,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    weight_decay = 0.01,\n",
        "    eval_strategy = 'epoch',\n",
        "    disable_tqdm = False,\n",
        "    logging_steps = logging_steps,\n",
        "    push_to_hub = True,\n",
        "    log_level = 'error'\n",
        ")"
      ],
      "metadata": {
        "id": "u-n4cKT0YRWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    compute_metrics = compute_metrics,\n",
        "    train_dataset = emotions_encoded['train'],\n",
        "    eval_dataset = emotions_encoded['validation'],\n",
        "    tokenizer = tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Ork1Kx26YRaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(emotions_encoded['validation'])"
      ],
      "metadata": {
        "id": "zPpXQLTQYReI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output"
      ],
      "metadata": {
        "id": "kKywgMHhY2lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output.metrics"
      ],
      "metadata": {
        "id": "WiGF6GgYY60A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(preds_output.predictions, axis = 1)"
      ],
      "metadata": {
        "id": "w_mIlzrZY80d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_preds, y_valid, labels.names)"
      ],
      "metadata": {
        "id": "Pf85CM2eY_kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aHeO51NAZHv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning with Keras"
      ],
      "metadata": {
        "id": "7iAK1eCbYRhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "tf_model = (TFAutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels = num_labels))"
      ],
      "metadata": {
        "id": "OG5HzGLFYYN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_columns = tokenizer.model_input_names\n",
        "\n",
        "tf_train_dataset = emotions_encoded['train'].to_tf_dataset(\n",
        "    columns = tokenizer_columns, label_cols = ['label'], shuffle = True,\n",
        "    batch_size = batch_size)\n",
        "tf_eval_dataset = emotions_encoded['validation'].to_tf_dataset(\n",
        "    columns = tokenizer_columns, label_cols = ['label'], shuffle = False,\n",
        "    batch_size = batch_size)"
      ],
      "metadata": {
        "id": "mm2syvgZYYec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf_model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    metrics = tf.metrics.SparseCategoricalAccuracy())\n",
        "\n",
        "tf_model.fit(tf_train_dataset, validation_data = tf_eval_dataset, epochs = 2)"
      ],
      "metadata": {
        "id": "XS6bRMmsZK9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MehlzMDpYYkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error Analysis"
      ],
      "metadata": {
        "id": "WhgUMwqBYYpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def forward_pass_with_labels(batch):\n",
        "    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
        "    with torch.no_grad():\n",
        "        output = model(**inputs)\n",
        "        pred_label = torch.argmax(output.logits, axis = -1)\n",
        "        loss = cross_entropy(output.logits, batch['label'].to(device),\n",
        "                             reduction = 'none')\n",
        "        return {'loss': loss.cpu().numpy(),\n",
        "                'predicted_label': pred_label.cpu().numpy()}"
      ],
      "metadata": {
        "id": "T4hYSuNWYdFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format('torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "emotions_encoded['validation'] = emotions_encoded['validation'].map(\n",
        "    forward_pass_with_labels, batched = True, batch_size = 16\n",
        ")"
      ],
      "metadata": {
        "id": "jlxWIMaQZU2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format('torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "emotions_encoded['validation'] = emotions_encoded['validation'].map(\n",
        "    forward_pass_with_labels, batched = True, batch_size = 16\n",
        ")"
      ],
      "metadata": {
        "id": "IKaNa8g1ZcMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format('pandas')\n",
        "cols = ['text', 'label', 'predicted_label', 'loss']\n",
        "df_test = emotions_encoded['validation'][:][cols]\n",
        "df_test['label'] = df_test['label'].apply(label_int2str)\n",
        "df_test['predicted_label'] = df_test['predicted_label'].apply(label_int2str)"
      ],
      "metadata": {
        "id": "1gnVKt6FZdp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values('loss', ascending = False)['text'].iloc[5]"
      ],
      "metadata": {
        "id": "Wy181JLaZfKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values('loss', ascending = False).head(10)"
      ],
      "metadata": {
        "id": "qHwv3gNOZgra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Sharing a model"
      ],
      "metadata": {
        "id": "RBCLIq-kYdqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message = 'Training completed!')"
      ],
      "metadata": {
        "id": "IB1oGDDJYjHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_id = 'neyvre/distilbert-base-uncased-finetuned-emotion'\n",
        "classifier = pipeline('text-classification', model = model_id)"
      ],
      "metadata": {
        "id": "eQIobJ6GZlGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = 'it was such a great movie, i loved the actors'\n",
        "preds = classifier(tweet, top_k = 6)\n",
        "preds"
      ],
      "metadata": {
        "id": "dY6LkFtJZqei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_df = pd.DataFrame(preds)\n",
        "preds_df_sorted = preds_df.sort_values('label', ascending = True)\n",
        "plt.bar(labels.names, 100 * preds_df_sorted['score'])\n",
        "plt.title(f'\"{tweet}\"')\n",
        "plt.ylabel('Prediction probability (%)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "swrtUh4vZsKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0cSIqE4BZtmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whRq0nOKYjLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JPgsSntlYjPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZgoZfTkFYjTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvVL1YnaYjWE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}